from typing import Dict, Any, Set, Tuple, List
import pandas as pd
import numpy as np
import io
from sqlalchemy.engine import Inspector
from openai import OpenAI
import logging
import json
import matplotlib.pyplot as plt
import seaborn as sns
import config
from config import API_KEY

client = OpenAI(api_key=API_KEY)


def analyze_single_table(table_name: str, df: pd.DataFrame) -> Dict[str, Any]:
    numeric_df = df.select_dtypes(include=np.number)
    corr = numeric_df.corr().replace({np.nan: None}).to_dict() if not numeric_df.empty else {}
    stats = df.describe(include='all').replace({np.nan: None}).to_json()

    prompt = (
        f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã '{table_name}'. "
        f"–í–æ—Ç –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}. "
        f"–í–æ—Ç –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π: {json.dumps(corr)}. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã—è–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã, —Å–∫—Ä—ã—Ç—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã. "
        "–ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –ø–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è Markdown –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è (`**—Ç–µ—Ä–º–∏–Ω**`)."
    )

    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4
    )
    insight = response.choices[0].message.content
    return {"insight": insight, "correlations": corr}


def analyze_joins(inspector: Inspector, dataframes: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
    joint_insights = {}
    analyzed_pairs: Set[Tuple[str, str]] = set()
    all_tables = list(dataframes.keys())

    for table_name in all_tables:
        try:
            foreign_keys = inspector.get_foreign_keys(table_name)
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∫–ª—é—á–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}: {e}")
            continue

        for fk in foreign_keys:
            left_table = table_name
            right_table = fk['referred_table']

            pair = tuple(sorted((left_table, right_table)))
            if pair in analyzed_pairs:
                continue

            analyzed_pairs.add(pair)

            df_left = dataframes[left_table]
            df_right = dataframes.get(right_table)

            if df_right is None:
                continue

            left_on = fk['constrained_columns']
            right_on = fk['referred_columns']

            try:
                merged_df = pd.merge(
                    df_left, df_right,
                    left_on=left_on,
                    right_on=right_on,
                    suffixes=(f'_{left_table}', f'_{right_table}')
                )

                if merged_df.empty:
                    continue

                join_key = f"{left_table} üîó {right_table}"
                analysis_result = analyze_single_table(join_key, merged_df)
                stats = merged_df.describe(include='all').replace({np.nan: None}).to_json()
                corr = analysis_result["correlations"]

                prompt = (
                    f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –°–í–Ø–ó–¨ –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∞–º–∏ '{left_table}' –∏ '{right_table}', –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –ø–æ –∫–ª—é—á–∞–º "
                    f"({left_table}.{','.join(left_on)} = {right_table}.{','.join(right_on)}). "
                    f"–í–æ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {stats}. "
                    f"–í–æ—Ç –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π: {json.dumps(corr)}. "
                    "–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –ø–æ–∏—Å–∫–µ –∏–Ω—Å–∞–π—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –∏–º–µ–Ω–Ω–æ –∏–∑-–∑–∞ —Å–≤—è–∑–∏ –¥–≤—É—Ö —Ç–∞–±–ª–∏—Ü. "
                    "–û—Ç–≤–µ—Ç –¥–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è Markdown –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è (`**—Ç–µ—Ä–º–∏–Ω**`)."
                )

                response = client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.5
                )

                analysis_result["insight"] = response.choices[0].message.content
                joint_insights[join_key] = analysis_result

            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–∞–±–ª–∏—Ü {left_table} –∏ {right_table}: {e}")

    return joint_insights


def generate_visualizations(
        dataframes: Dict[str, pd.DataFrame], report_id: int
) -> Dict[str, List[str]]:
    visualizations = {}
    sns.set_theme(style="whitegrid")

    for name, df in dataframes.items():
        if df.empty:
            continue

        safe_name = "".join(c if c.isalnum() else "_" for c in name)
        df_info = df.dtypes.to_string()

        # –ò–ó–ú–ï–ù–ï–ù–ò–ï: –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è JSON Mode
        prompt = (
            f"–î–ª—è DataFrame —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º '{name}' –∏ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π —Å—Ç–æ–ª–±—Ü–æ–≤:\n{df_info}\n\n"
            "–ü—Ä–µ–¥–ª–æ–∂–∏ –¥–æ 2 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö. "
            "–û—Ç–≤–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –≤ –≤–∏–¥–µ JSON-–æ–±—ä–µ–∫—Ç–∞ —Å –∫–ª—é—á–æ–º 'charts', –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Å—Å–∏–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. "
            "–ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –≤ –º–∞—Å—Å–∏–≤–µ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å: 'chart_type' ('hist', 'bar', 'scatter', 'pie'), "
            "'columns' (—Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤), –∏ 'title' (–Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º). "
            "–í—ã–±–∏—Ä–∞–π —Å—Ç–æ–ª–±—Ü—ã —Å —É–º–æ–º. –ù–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π scatter –µ—Å–ª–∏ –Ω–µ—Ç –¥–≤—É—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏–ª–∏ pie –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å >10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π. "
            "–ü—Ä–∏–º–µ—Ä: {\"charts\": [{\"chart_type\": \"bar\", \"columns\": [\"col1\", \"col2\"], \"title\": \"–ü—Ä–∏–º–µ—Ä\"}]}"
        )

        try:
            response = client.chat.completions.create(
                model="gpt-4.1-nano",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            response_data = json.loads(response.choices[0].message.content)
            chart_ideas = response_data.get("charts", [])

            if not chart_ideas:
                logging.warning(f"GPT –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∏–¥–µ–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è '{name}'.")
                continue

            chart_urls = []
            for i, idea in enumerate(chart_ideas):
                plt.figure(figsize=(10, 6))
                chart_type, columns, title = idea.get("chart_type"), idea.get("columns", []), idea.get("title",
                                                                                                       "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫")

                try:
                    if chart_type == 'hist' and len(columns) == 1 and pd.api.types.is_numeric_dtype(df[columns[0]]):
                        sns.histplot(df, x=columns[0], kde=True)
                    elif chart_type == 'bar' and len(columns) == 2:
                        top_15 = df.groupby(columns[0])[columns[1]].sum().nlargest(15)
                        sns.barplot(x=top_15.index, y=top_15.values)
                        plt.xticks(rotation=45, ha='right')
                    elif chart_type == 'scatter' and len(columns) == 2 and all(
                            pd.api.types.is_numeric_dtype(df[c]) for c in columns):
                        sns.scatterplot(df, x=columns[0], y=columns[1])
                    elif chart_type == 'pie' and len(columns) == 1 and df[columns[0]].nunique() <= 10:
                        df[columns[0]].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, counterclock=False)
                        plt.ylabel('')
                    else:
                        continue

                    plt.title(title)
                    plt.tight_layout()

                    buffer = io.BytesIO()
                    plt.savefig(buffer, format='png', bbox_inches='tight')
                    buffer.seek(0)

                    s3_key = f"charts/{report_id}/{safe_name}_{i}.png"

                    config.s3_client.put_object(
                        Bucket=config.S3_BUCKET_NAME, Key=s3_key, Body=buffer, ContentType='image/png'
                    )

                    presigned_url = config.s3_client.generate_presigned_url(
                        'get_object', Params={'Bucket': config.S3_BUCKET_NAME, 'Key': s3_key}, ExpiresIn=360000000
                    )
                    chart_urls.append(presigned_url)
                except Exception as e:
                    logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ '{title}': {e}", exc_info=True)
                finally:
                    plt.close()

            if chart_urls:
                visualizations[name] = chart_urls

        except json.JSONDecodeError:
            logging.error(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç OpenAI –¥–ª—è '{name}'. –û—Ç–≤–µ—Ç: {response.choices[0].message.content}")
        except Exception as e:
            logging.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è '{name}': {e}")

    return visualizations


def perform_full_analysis(
        inspector: Inspector, dataframes: Dict[str, pd.DataFrame], report_id: int
) -> Dict[str, Any]:
    single_table_analysis = {}
    for table, df in dataframes.items():
        single_table_analysis[table] = analyze_single_table(table, df)

    joint_table_analysis = analyze_joins(inspector, dataframes)
    visualizations = generate_visualizations(dataframes.copy(), report_id)

    def clean_nan(obj):
        if isinstance(obj, dict): return {k: clean_nan(v) for k, v in obj.items()}
        if isinstance(obj, list): return [clean_nan(item) for item in obj]
        if isinstance(obj, float) and np.isnan(obj): return None
        return obj

    return clean_nan({
        "single_table_insights": single_table_analysis,
        "joint_table_insights": joint_table_analysis,
        "visualizations": visualizations
    })