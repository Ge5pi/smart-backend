from typing import Dict, Any, Set, Tuple, List
import pandas as pd
import numpy as np
import io
from sqlalchemy.engine import Inspector
from openai import OpenAI
import logging
import json
import matplotlib.pyplot as plt
import seaborn as sns
import config
from config import API_KEY

client = OpenAI(api_key=API_KEY)

S3_PRESIGNED_URL_EXPIRATION_ONE_YEAR = 365 * 24 * 60 * 60

def analyze_single_table(table_name: str, df: pd.DataFrame) -> Dict[str, Any]:
    numeric_df = df.select_dtypes(include=np.number)
    corr = numeric_df.corr().replace({np.nan: None}).to_dict() if not numeric_df.empty else {}
    stats = df.describe(include='all').replace({np.nan: None}).to_json()

    prompt = (
        f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã '{table_name}'. "
        f"–í–æ—Ç –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}. "
        f"–í–æ—Ç –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π: {json.dumps(corr)}. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã—è–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã, —Å–∫—Ä—ã—Ç—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã. "
        "–ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –ø–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è Markdown –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è (`**—Ç–µ—Ä–º–∏–Ω**`)."
    )

    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4
    )
    insight = response.choices[0].message.content
    return {"insight": insight, "correlations": corr}


def analyze_joins(inspector: Inspector, dataframes: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
    joint_insights = {}
    analyzed_pairs: Set[Tuple[str, str]] = set()
    all_tables = list(dataframes.keys())

    for table_name in all_tables:
        try:
            foreign_keys = inspector.get_foreign_keys(table_name)
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∫–ª—é—á–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}: {e}")
            continue

        for fk in foreign_keys:
            left_table = table_name
            right_table = fk['referred_table']

            pair = tuple(sorted((left_table, right_table)))
            if pair in analyzed_pairs:
                continue

            analyzed_pairs.add(pair)

            df_left = dataframes[left_table]
            df_right = dataframes.get(right_table)

            if df_right is None:
                continue

            left_on = fk['constrained_columns']
            right_on = fk['referred_columns']

            try:
                merged_df = pd.merge(
                    df_left, df_right,
                    left_on=left_on,
                    right_on=right_on,
                    suffixes=(f'_{left_table}', f'_{right_table}')
                )

                if merged_df.empty:
                    continue

                join_key = f"{left_table} üîó {right_table}"
                analysis_result = analyze_single_table(join_key, merged_df)
                stats = merged_df.describe(include='all').replace({np.nan: None}).to_json()
                corr = analysis_result["correlations"]

                prompt = (
                    f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –°–í–Ø–ó–¨ –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∞–º–∏ '{left_table}' –∏ '{right_table}', –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –ø–æ –∫–ª—é—á–∞–º "
                    f"({left_table}.{','.join(left_on)} = {right_table}.{','.join(right_on)}). "
                    f"–í–æ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {stats}. "
                    f"–í–æ—Ç –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π: {json.dumps(corr)}. "
                    "–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –ø–æ–∏—Å–∫–µ –∏–Ω—Å–∞–π—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –∏–º–µ–Ω–Ω–æ –∏–∑-–∑–∞ —Å–≤—è–∑–∏ –¥–≤—É—Ö —Ç–∞–±–ª–∏—Ü. "
                    "–û—Ç–≤–µ—Ç –¥–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è Markdown –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è (`**—Ç–µ—Ä–º–∏–Ω**`)."
                )

                response = client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.5
                )

                analysis_result["insight"] = response.choices[0].message.content
                joint_insights[join_key] = analysis_result

            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–∞–±–ª–∏—Ü {left_table} –∏ {right_table}: {e}")

    return joint_insights


def generate_visualizations(
        dataframes: Dict[str, pd.DataFrame], report_id: int
) -> Dict[str, List[str]]:
    visualizations = {}
    sns.set_theme(style="whitegrid")

    for name, df in dataframes.items():
        if df.empty:
            continue

        safe_name = "".join(c if c.isalnum() else "_" for c in name)

        # Prepare column info for GPT more explicitly, including types for better suggestions
        column_info = [{"name": col, "dtype": str(df[col].dtype), "nunique": df[col].nunique(),
                        "is_numeric": pd.api.types.is_numeric_dtype(df[col])} for col in df.columns]

        prompt = (
            f"–î–ª—è DataFrame —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º '{name}' –∏ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π —Å—Ç–æ–ª–±—Ü–æ–≤: {json.dumps(column_info)}. "
            "–ü—Ä–µ–¥–ª–æ–∂–∏ –¥–æ 2 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö. "
            "–û—Ç–≤–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –≤ –≤–∏–¥–µ JSON-–æ–±—ä–µ–∫—Ç–∞ —Å –∫–ª—é—á–æ–º 'charts', –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Å—Å–∏–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. "
            "–ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –≤ –º–∞—Å—Å–∏–≤–µ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å: 'chart_type' ('hist', 'bar', 'scatter', 'pie'), "
            "'columns' (–°–ü–ò–°–û–ö –°–£–©–ï–°–¢–í–£–Æ–©–ò–• –°–¢–û–õ–ë–¶–û–í, –í–´–ë–†–ê–ù–ù–´–• –ò–ó –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –°–ü–ò–°–ö–ê), –∏ 'title' (–Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º). "
            "–í—ã–±–∏—Ä–∞–π —Å—Ç–æ–ª–±—Ü—ã —Å —É–º–æ–º. –ù–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π scatter –µ—Å–ª–∏ –Ω–µ—Ç –¥–≤—É—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏–ª–∏ pie –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å >10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π. "
            "–ü—Ä–∏–º–µ—Ä: {\"charts\": [{\"chart_type\": \"bar\", \"columns\": [\"col1\", \"col2\"], \"title\": \"–ü—Ä–∏–º–µ—Ä\"}]}"
        )

        try:
            response = client.chat.completions.create(
                model="gpt-4.1-nano",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            response_data = json.loads(response.choices[0].message.content)
            chart_ideas = response_data.get("charts", [])

            if not chart_ideas:
                logging.warning(f"GPT –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∏–¥–µ–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è '{name}'.")
                continue

            chart_urls = []
            for i, idea in enumerate(chart_ideas):
                plt.figure(figsize=(10, 6))
                chart_type, columns, title = idea.get("chart_type"), idea.get("columns", []), idea.get("title",
                                                                                                       "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫")

                # Ensure all proposed columns exist
                if not all(col in df.columns for col in columns):
                    logging.warning(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ '{title}' –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã '{name}': –û–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ ({', '.join(columns)}) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ DataFrame.")
                    plt.close()
                    continue

                # Create a copy for plotting to avoid modifying the original dataframe in case of type conversion
                plot_df = df.copy()

                try:
                    if chart_type == 'hist' and len(columns) == 1:
                        col = columns[0]
                        # Attempt to convert to numeric, coerce errors to NaN, then drop NaNs for plotting
                        plot_df[col] = pd.to_numeric(plot_df[col], errors='coerce')
                        if pd.api.types.is_numeric_dtype(plot_df[col]):
                            sns.histplot(plot_df.dropna(subset=[col]), x=col, kde=True)
                        else:
                            logging.warning(
                                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –¥–ª—è '{col}': –°—Ç–æ–ª–±–µ—Ü –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")
                            plt.close()
                            continue
                    elif chart_type == 'bar' and len(columns) == 2:
                        x_col, y_col = columns[0], columns[1]
                        # Attempt to convert y_col to numeric
                        plot_df[y_col] = pd.to_numeric(plot_df[y_col], errors='coerce')

                        if pd.api.types.is_numeric_dtype(plot_df[y_col]):
                            # Filter out NaN in relevant columns for grouping/summing
                            temp_df = plot_df.dropna(subset=[x_col, y_col])
                            if not temp_df.empty:
                                top_15 = temp_df.groupby(x_col)[y_col].sum().nlargest(15)
                                sns.barplot(x=top_15.index, y=top_15.values)
                                plt.xticks(rotation=45, ha='right')
                            else:
                                logging.warning(
                                    f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å—Ç–æ–ª–±—á–∞—Ç–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã –¥–ª—è '{x_col}' –∏ '{y_col}' –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN.")
                                plt.close()
                                continue
                        else:
                            logging.warning(
                                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å—Ç–æ–ª–±—á–∞—Ç—É—é –¥–∏–∞–≥—Ä–∞–º–º—É –¥–ª—è '{y_col}': –°—Ç–æ–ª–±–µ—Ü –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")
                            plt.close()
                            continue
                    elif chart_type == 'scatter' and len(columns) == 2:
                        x_col, y_col = columns[0], columns[1]
                        # Attempt to convert both columns to numeric
                        plot_df[x_col] = pd.to_numeric(plot_df[x_col], errors='coerce')
                        plot_df[y_col] = pd.to_numeric(plot_df[y_col], errors='coerce')

                        if pd.api.types.is_numeric_dtype(plot_df[x_col]) and pd.api.types.is_numeric_dtype(
                                plot_df[y_col]):
                            # Drop NaNs for scatter plot
                            sns.scatterplot(plot_df.dropna(subset=[x_col, y_col]), x=x_col, y=y_col)
                        else:
                            logging.warning(
                                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–æ—á–µ—á–Ω—É—é –¥–∏–∞–≥—Ä–∞–º–º—É –¥–ª—è '{x_col}' –∏ '{y_col}': –û–¥–∏–Ω –∏–ª–∏ –æ–±–∞ —Å—Ç–æ–ª–±—Ü–∞ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")
                            plt.close()
                            continue
                    elif chart_type == 'pie' and len(columns) == 1:
                        col = columns[0]
                        # For pie, ensure the column is suitable (e.g., categorical or low unique values)
                        # The nunique check is already in the prompt, but an explicit check here is good
                        if plot_df[
                            col].nunique() <= 10:  # Re-check the nunique after potential conversion or for robustness
                            plot_df[col].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, counterclock=False)
                            plt.ylabel('')  # Remove y-label for pie chart
                        else:
                            logging.warning(
                                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫—Ä—É–≥–æ–≤—É—é –¥–∏–∞–≥—Ä–∞–º–º—É –¥–ª—è '{col}': –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (>10).")
                            plt.close()
                            continue
                    else:
                        logging.warning(
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ '{title}' –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã '{name}': –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ ({chart_type}) –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤ ({len(columns)}).")
                        plt.close()
                        continue

                    plt.title(title)
                    plt.tight_layout()

                    buffer = io.BytesIO()
                    plt.savefig(buffer, format='png', bbox_inches='tight')
                    buffer.seek(0)

                    s3_key = f"charts/{report_id}/{safe_name}_{i}.png"

                    config.s3_client.put_object(
                        Bucket=config.S3_BUCKET_NAME, Key=s3_key, Body=buffer, ContentType='image/png'
                    )

                    presigned_url = config.s3_client.generate_presigned_url(
                        'get_object', Params={'Bucket': config.S3_BUCKET_NAME, 'Key': s3_key},
                        ExpiresIn=S3_PRESIGNED_URL_EXPIRATION_ONE_YEAR
                    )
                    chart_urls.append(presigned_url)
                except Exception as e:
                    logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ '{title}': {e}", exc_info=True)
                finally:
                    plt.close()  # Always close the plot to free memory

            if chart_urls:
                visualizations[name] = chart_urls

        except json.JSONDecodeError:
            logging.error(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç OpenAI –¥–ª—è '{name}'. –û—Ç–≤–µ—Ç: {response.choices[0].message.content}")
        except Exception as e:
            logging.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è '{name}': {e}")

    return visualizations


def perform_full_analysis(
        inspector: Inspector, dataframes: Dict[str, pd.DataFrame], report_id: int
) -> Dict[str, Any]:
    single_table_analysis = {}
    for table, df in dataframes.items():
        single_table_analysis[table] = analyze_single_table(table, df)

    joint_table_analysis = analyze_joins(inspector, dataframes)
    visualizations = generate_visualizations(dataframes.copy(), report_id)

    def clean_nan(obj):
        if isinstance(obj, dict): return {k: clean_nan(v) for k, v in obj.items()}
        if isinstance(obj, list): return [clean_nan(item) for item in obj]
        if isinstance(obj, float) and np.isnan(obj): return None
        return obj

    return clean_nan({
        "single_table_insights": single_table_analysis,
        "joint_table_insights": joint_table_analysis,
        "visualizations": visualizations
    })