# tasks.py - SmartGPT DataFrame —Å–∏—Å—Ç–µ–º–∞

import logging
from typing import List, Dict, Any
import numpy as np
from celery.exceptions import Ignore
from sqlalchemy import create_engine, text
import crud
import database
from services.dataframe_manager import DataFrameManager
from services.dataframe_analyzer import DataFrameAnalyzer
from services.gpt_analyzer import SmartGPTAnalyzer  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç
from utils.json_serializer import convert_to_serializable
from celery_worker import celery_app
from datetime import datetime, timedelta
import json
import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logger = logging.getLogger(__name__)


@celery_app.task(bind=True, time_limit=7200, name='tasks.generate_dataframe_report')
def generate_dataframe_report(self, connection_id: int, user_id: int, report_id: int, max_questions: int = 15):
    """–û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SmartGPT DataFrame –æ—Ç—á–µ—Ç–∞"""

    db_session = next(database.get_db())

    try:
        logger.info(f"[SMARTGPT DATAFRAME] üöÄ –ó–∞–ø—É—Å–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, –æ—Ç—á–µ—Ç {report_id}")

        # === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===
        self.update_state(
            state='INITIALIZING',
            meta={'progress': 'üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SmartGPT DataFrame —Å–∏—Å—Ç–µ–º—ã...', 'progress_percentage': 5}
        )

        connection_string = crud.get_decrypted_connection_string(db_session, connection_id, user_id)
        if not connection_string:
            raise ValueError("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")

        engine = create_engine(connection_string, connect_args={'connect_timeout': 60})

        # === –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
        self.update_state(
            state='LOADING_DATA',
            meta={'progress': 'üìä –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü –≤ –ø–∞–º—è—Ç—å –¥–ª—è SmartGPT –∞–Ω–∞–ª–∏–∑–∞...', 'progress_percentage': 10}
        )

        df_manager = DataFrameManager(engine)
        tables_loaded = df_manager.load_all_tables(max_rows_per_table=50000)

        if not tables_loaded:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–ª—è SmartGPT –∞–Ω–∞–ª–∏–∑–∞")

        logger.info(f"[SMARTGPT DATAFRAME] ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(tables_loaded)} —Ç–∞–±–ª–∏—Ü")

        # === –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ò –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê–¢–û–†–û–í ===
        self.update_state(
            state='OPTIMIZING',
            meta={'progress': '‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SmartGPT...', 'progress_percentage': 20}
        )

        df_manager.optimize_memory()
        analyzer = DataFrameAnalyzer(df_manager)
        smart_gpt = SmartGPTAnalyzer()

        # === –°–û–ó–î–ê–ù–ò–ï –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ì–û –ü–õ–ê–ù–ê ===
        self.update_state(
            state='PLANNING',
            meta={'progress': 'üß† –°–æ–∑–¥–∞–Ω–∏–µ —É–º–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å GPT –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π...', 'progress_percentage': 25}
        )

        analysis_plan = _create_smartgpt_analysis_plan(df_manager, max_questions)
        logger.info(f"[SMARTGPT DATAFRAME] üìã –ü–ª–∞–Ω —Å–æ–∑–¥–∞–Ω: {len(analysis_plan)} —É–º–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")

        # === –í–´–ü–û–õ–ù–ï–ù–ò–ï SMARTGPT –ê–ù–ê–õ–ò–ó–ê ===
        smartgpt_findings = []
        successful_analyses = 0
        gpt_insights_count = 0

        for i, question_config in enumerate(analysis_plan):
            if i >= max_questions:
                break

            progress = 25 + (i + 1) / min(len(analysis_plan), max_questions) * 60  # 25-85%
            question = question_config.get('question', str(question_config))
            analysis_type = question_config.get('type', 'general')
            enable_gpt = question_config.get('enable_gpt', True)

            self.update_state(
                state='SMART_ANALYZING',
                meta={
                    'progress': f'ü§ñ SmartGPT –∞–Ω–∞–ª–∏–∑ {i + 1}/{min(len(analysis_plan), max_questions)}: {question[:60]}...',
                    'progress_percentage': progress,
                    'analysis_type': analysis_type
                }
            )

            logger.info(f"[SMARTGPT DATAFRAME] üîç –ê–Ω–∞–ª–∏–∑ {i + 1}: {question} (—Ç–∏–ø: {analysis_type})")

            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º DataFrame –∞–Ω–∞–ª–∏–∑
                result = analyzer.analyze_question(question)

                if not result.get('error'):
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    data_preview = result.get('data', [])
                    if hasattr(data_preview, 'head'):
                        data_preview = convert_to_serializable(data_preview.head(10).to_dict('records'))
                    elif isinstance(data_preview, (list, dict)):
                        data_preview = convert_to_serializable(data_preview)
                    else:
                        data_preview = []

                    # === SMARTGPT –û–ë–û–ì–ê–©–ï–ù–ò–ï ===
                    smartgpt_insights = {}
                    if enable_gpt and data_preview and result.get('analyzed_tables'):
                        try:
                            main_table = result['analyzed_tables'][0]
                            df_for_gpt = df_manager.tables[main_table]

                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø SmartGPT –∞–Ω–∞–ª–∏–∑–∞
                            gpt_type = _map_analysis_to_smartgpt_type(question, analysis_type)

                            # –°–æ–∑–¥–∞–µ–º –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç
                            business_context = {
                                'question': question,
                                'dataframe_results': result,
                                'analysis_type': analysis_type,
                                'table_focus': main_table,
                                'user_intent': _extract_user_intent(question)
                            }

                            # –ü–æ–ª—É—á–∞–µ–º SmartGPT –∏–Ω—Å–∞–π—Ç—ã
                            gpt_result = smart_gpt.analyze_findings_with_context(df=df_for_gpt,
                                                                                 dataframe_results=result,
                                                                                 business_context=business_context
                                                                                 )

                            smartgpt_insights = {
                                'business_insights': gpt_result.get('business_insights', ''),
                                'action_items': gpt_result.get('action_items', []),
                                'risk_assessment': gpt_result.get('risk_assessment', ''),
                                'opportunities': gpt_result.get('opportunities', []),
                                'confidence': gpt_result.get('confidence', 'medium'),
                                'business_context': gpt_result.get('business_context', {})
                            }

                            gpt_insights_count += 1
                            logger.info(f"[SMARTGPT] ‚ú® –£–º–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –ø–æ–ª—É—á–µ–Ω—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ {i + 1}")

                        except Exception as gpt_error:
                            logger.error(f"[SMARTGPT] ‚ùå –û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ {i + 1}: {gpt_error}")
                            smartgpt_insights = {
                                'business_insights': f'SmartGPT –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(gpt_error)}',
                                'confidence': 'low'
                            }

                    # –°–æ–∑–¥–∞–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                    finding_entry = {
                        'question': str(question),
                        'summary': str(result.get('summary', '')),
                        'data_preview': data_preview[:10],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                        'chart_data': convert_to_serializable(result.get('chart_data')),
                        'analyzed_tables': list(result.get('analyzed_tables', [])),
                        'method': 'smartgpt_dataframe_v2',
                        'analysis_type': analysis_type,

                        # SmartGPT –æ–±–æ–≥–∞—â–µ–Ω–∏–µ
                        'smartgpt_insights': smartgpt_insights,
                        'has_gpt_insights': bool(smartgpt_insights.get('business_insights')),

                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        'additional_info': convert_to_serializable(result.get('additional_info', {})),
                        'correlations': convert_to_serializable(result.get('correlations', [])),
                        'anomalies': convert_to_serializable(result.get('anomalies', [])),
                        'business_metrics': convert_to_serializable(result.get('business_metrics', {})),

                        'timestamp': datetime.now().isoformat(),
                        'success': True,
                        'smartgpt_enabled': enable_gpt
                    }

                    # –û–±–Ω–æ–≤–ª—è–µ–º summary —Å SmartGPT –∏–Ω—Å–∞–π—Ç–∞–º–∏
                    if smartgpt_insights.get('business_insights'):
                        enhanced_summary = f"ü§ñ **SmartGPT –ò–Ω—Å–∞–π—Ç—ã:**\n{smartgpt_insights['business_insights']}\n\nüìä **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:**\n{result.get('summary', '')}"
                        finding_entry['summary'] = enhanced_summary

                    smartgpt_findings.append(finding_entry)
                    successful_analyses += 1

                    logger.info(
                        f"[SMARTGPT DATAFRAME] ‚úÖ –ê–Ω–∞–ª–∏–∑ {i + 1} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ (GPT: {'‚ú®' if smartgpt_insights.get('business_insights') else '‚ùå'})")

                else:
                    error_msg = str(result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'))
                    logger.error(f"[SMARTGPT DATAFRAME] ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {i + 1}: {error_msg}")

                    smartgpt_findings.append({
                        'question': str(question),
                        'summary': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_msg}',
                        'data_preview': [],
                        'error': error_msg,
                        'method': 'smartgpt_dataframe_v2',
                        'analysis_type': analysis_type,
                        'success': False,
                        'has_gpt_insights': False,
                        'timestamp': datetime.now().isoformat()
                    })

            except Exception as analysis_error:
                error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ SmartGPT –∞–Ω–∞–ª–∏–∑–∞: {str(analysis_error)}"
                logger.error(f"[SMARTGPT DATAFRAME] üí• {error_msg}")

                smartgpt_findings.append({
                    'question': str(question),
                    'summary': error_msg,
                    'data_preview': [],
                    'error': error_msg,
                    'method': 'smartgpt_dataframe_v2',
                    'analysis_type': analysis_type,
                    'success': False,
                    'has_gpt_insights': False,
                    'timestamp': datetime.now().isoformat()
                })

        # === –°–û–ó–î–ê–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ì–û SMARTGPT –û–¢–ß–ï–¢–ê ===
        self.update_state(
            state='FINALIZING',
            meta={'progress': 'üìù –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ SmartGPT –æ—Ç—á–µ—Ç–∞...', 'progress_percentage': 85}
        )

        logger.info(
            f"[SMARTGPT DATAFRAME] üìä –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {successful_analyses}/{len(smartgpt_findings)} —É—Å–ø–µ—à–Ω—ã—Ö, {gpt_insights_count} SmartGPT –∏–Ω—Å–∞–π—Ç–æ–≤")

        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ –¥–∞–Ω–Ω—ã–º
        table_summary = df_manager.get_table_summary()
        memory_info = df_manager.get_memory_usage()

        # === SMARTGPT EXECUTIVE SUMMARY ===
        executive_summary = ""
        try:
            if successful_analyses > 0 and gpt_insights_count > 0:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω–æ–µ executive summary
                executive_summary = smart_gpt.generate_executive_summary(
                    smartgpt_findings, table_summary
                )
            else:
                executive_summary = _create_fallback_executive_summary(
                    smartgpt_findings, table_summary, successful_analyses
                )
        except Exception as summary_error:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è SmartGPT executive summary: {summary_error}")
            executive_summary = _create_fallback_executive_summary(
                smartgpt_findings, table_summary, successful_analyses
            )

        # === –§–ò–ù–ê–õ–¨–ù–´–ô SMARTGPT –û–¢–ß–ï–¢ ===
        final_smartgpt_report = {
            "executive_summary": str(executive_summary),
            "detailed_findings": convert_to_serializable(smartgpt_findings),
            "method": "smartgpt_dataframe_v2",
            "tables_info": convert_to_serializable(table_summary['tables']),
            "relations_info": convert_to_serializable(table_summary['relations']),

            "smartgpt_analysis_stats": {
                "questions_processed": int(len(smartgpt_findings)),
                "successful_analyses": int(successful_analyses),
                "failed_analyses": int(len(smartgpt_findings) - successful_analyses),
                "smartgpt_insights_count": int(gpt_insights_count),
                "tables_analyzed": int(table_summary['total_tables']),
                "relations_found": int(table_summary['total_relations']),
                "total_memory_mb": round(float(table_summary['total_memory_mb']), 2),
                "success_rate_percent": round(float(successful_analyses / max(len(smartgpt_findings), 1) * 100), 1),
                "smartgpt_coverage_percent": round(float(gpt_insights_count / max(successful_analyses, 1) * 100), 1)
            },

            "memory_usage": convert_to_serializable(memory_info),
            "smartgpt_recommendations": [str(r) for r in _generate_smartgpt_recommendations(
                smartgpt_findings, table_summary, successful_analyses, gpt_insights_count
            )],

            "report_metadata": {
                "created_at": datetime.now().isoformat(),
                "user_id": int(user_id),
                "connection_id": int(connection_id),
                "report_version": "3.0_smartgpt_dataframe",
                "max_questions_requested": int(max_questions),
                "smartgpt_enabled": True,
                "analysis_engine": "SmartGPTAnalyzer"
            }
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ—Ç—á–µ—Ç–∞
        try:
            report_json = json.dumps(final_smartgpt_report, ensure_ascii=False)
            report_size_mb = len(report_json.encode('utf-8')) / 1024 / 1024
            logger.info(f"[SMARTGPT DATAFRAME] üìè –†–∞–∑–º–µ—Ä SmartGPT –æ—Ç—á–µ—Ç–∞: {report_size_mb:.2f} MB")

            if report_size_mb > 12:  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è SmartGPT –æ—Ç—á–µ—Ç–æ–≤
                logger.warning(f"[SMARTGPT DATAFRAME] ‚ö†Ô∏è –û—Ç—á–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({report_size_mb:.2f} MB), —Å–æ–∫—Ä–∞—â–∞–µ–º")
                final_smartgpt_report = _trim_smartgpt_report(final_smartgpt_report)

        except Exception as json_error:
            logger.error(f"[SMARTGPT DATAFRAME] ‚ùå –û—à–∏–±–∫–∞ JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {json_error}")
            final_smartgpt_report = convert_to_serializable(final_smartgpt_report)

        # === –°–û–•–†–ê–ù–ï–ù–ò–ï SMARTGPT –û–¢–ß–ï–¢–ê ===
        self.update_state(
            state='SAVING',
            meta={'progress': 'üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ SmartGPT –æ—Ç—á–µ—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...', 'progress_percentage': 95}
        )

        try:
            crud.update_report(db_session, report_id, "COMPLETED", final_smartgpt_report)
            logger.info(f"[SMARTGPT DATAFRAME] ‚úÖ SmartGPT –æ—Ç—á–µ—Ç {report_id} —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")

        except Exception as save_error:
            logger.error(f"[SMARTGPT DATAFRAME] ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è SmartGPT –æ—Ç—á–µ—Ç–∞: {save_error}")
            # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
            try:
                simplified_report = {
                    "executive_summary": final_smartgpt_report["executive_summary"],
                    "method": "smartgpt_dataframe_v2",
                    "smartgpt_analysis_stats": final_smartgpt_report["smartgpt_analysis_stats"],
                    "error": f"–ü–æ–ª–Ω—ã–π SmartGPT –æ—Ç—á–µ—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {str(save_error)}",
                    "report_metadata": final_smartgpt_report["report_metadata"]
                }
                crud.update_report(db_session, report_id, "COMPLETED", simplified_report)
                logger.warning(f"[SMARTGPT DATAFRAME] ‚ö†Ô∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π SmartGPT –æ—Ç—á–µ—Ç {report_id}")
            except Exception as final_save_error:
                logger.error(f"[SMARTGPT DATAFRAME] üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {final_save_error}")
                raise

        self.update_state(
            state='SUCCESS',
            meta={'progress': 'üéâ SmartGPT DataFrame –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!', 'progress_percentage': 100}
        )

        return {
            "status": "success",
            "report_id": report_id,
            "questions_processed": len(smartgpt_findings),
            "successful_analyses": successful_analyses,
            "smartgpt_insights": gpt_insights_count,
            "tables_loaded": len(tables_loaded),
            "method": "smartgpt_dataframe_v2"
        }

    except Exception as e:
        logger.error(f"[SMARTGPT DATAFRAME ERROR] üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
        error_report = {
            "error": str(e),
            "method": "smartgpt_dataframe_v2",
            "stage": "critical_error",
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "connection_id": connection_id,
            "smartgpt_enabled": True
        }

        try:
            crud.update_report(db_session, report_id, "FAILED", error_report)
        except Exception as save_error:
            logger.error(f"[SMARTGPT DATAFRAME] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—à–∏–±–∫—É: {save_error}")

        self.update_state(
            state='FAILURE',
            meta={
                'progress': f'üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ SmartGPT: {str(e)}',
                'error': str(e),
                'progress_percentage': 0
            }
        )

        raise e

    finally:
        try:
            db_session.close()
        except:
            pass


def _create_smartgpt_analysis_plan(df_manager: DataFrameManager, max_questions: int) -> List[Dict[str, Any]]:
    """–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è SmartGPT"""

    plan = [
        {
            'question': 'üè† –£–º–Ω—ã–π –æ–±–∑–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ —Å–∫—Ä—ã—Ç—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏',
            'type': 'overview',
            'enable_gpt': True,
            'priority': 1
        }
    ]

    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü —Å SmartGPT –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π
    tables_by_size = sorted(df_manager.tables.items(), key=lambda x: len(x[1]), reverse=True)

    for i, (table_name, df) in enumerate(tables_by_size[:min(4, len(tables_by_size))]):
        if i < 2:  # –ü–µ—Ä–≤—ã–µ 2 —Ç–∞–±–ª–∏—Ü—ã - –¥–µ—Ç–∞–ª—å–Ω—ã–π SmartGPT –∞–Ω–∞–ª–∏–∑
            plan.extend([
                {
                    'question': f"üíº –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã '{table_name}' —Å –≤—ã—è–≤–ª–µ–Ω–∏–µ–º —Å–∫—Ä—ã—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π",
                    'type': 'business_insights',
                    'table_focus': table_name,
                    'enable_gpt': True,
                    'priority': 1 if i == 0 else 2
                },
                {
                    'question': f"üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü—ã '{table_name}' —Å —É–º–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é",
                    'type': 'data_quality',
                    'table_focus': table_name,
                    'enable_gpt': True,
                    'priority': 2
                }
            ])
        else:  # –û—Å—Ç–∞–ª—å–Ω—ã–µ - —ç–∫—Å–ø—Ä–µ—Å—Å-–∞–Ω–∞–ª–∏–∑
            plan.append({
                'question': f"‚ö° –≠–∫—Å–ø—Ä–µ—Å—Å-–∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã '{table_name}' —Å –∫–ª—é—á–µ–≤—ã–º–∏ –∏–Ω—Å–∞–π—Ç–∞–º–∏",
                'type': 'table_analysis',
                'table_focus': table_name,
                'enable_gpt': True,
                'priority': 3
            })

    # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SmartGPT –∞–Ω–∞–ª–∏–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    has_numeric_data = any(
        len(df.select_dtypes(include=[np.number]).columns) > 0
        for df in df_manager.tables.values()
    )

    has_datetime_data = any(
        any('date' in col.lower() or 'time' in col.lower() for col in df.columns)
        for df in df_manager.tables.values()
    )

    if has_numeric_data:
        plan.extend([
            {
                'question': 'üìä –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å SmartGPT –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–µ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤',
                'type': 'statistical_insights',
                'enable_gpt': True,
                'priority': 2
            },
            {
                'question': 'üîó –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å –±–∏–∑–Ω–µ—Å-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–µ–π –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –≤—ã–≤–æ–¥–∞–º–∏',
                'type': 'correlation',
                'enable_gpt': True,
                'priority': 2
            }
        ])

    if has_datetime_data:
        plan.append({
            'question': 'üìà –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏',
            'type': 'trend_analysis',
            'enable_gpt': True,
            'priority': 2
        })

    # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∞–º–∏
    if df_manager.relations:
        plan.append({
            'question': 'üåê –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Å–≤—è–∑–µ–π —Å —É–º–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏',
            'type': 'relationship_analysis',
            'enable_gpt': True,
            'priority': 2
        })

    # –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    plan.extend([
        {
            'question': 'üö® –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø—Ä–∏—á–∏–Ω –∏ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –±–∏–∑–Ω–µ—Å',
            'type': 'anomalies',
            'enable_gpt': True,
            'priority': 3
        },
        {
            'question': '‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü —Å –≤—ã—è–≤–ª–µ–Ω–∏–µ–º —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤',
            'type': 'comparison',
            'enable_gpt': True,
            'priority': 3
        }
    ])

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ SmartGPT –∞–Ω–∞–ª–∏–∑—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–ª–∞–Ω–æ–≤
    if max_questions > 15:
        plan.extend([
            {
                'question': 'üöÄ –ü–æ–∏—Å–∫ —Å–∫—Ä—ã—Ç—ã—Ö –±–∏–∑–Ω–µ—Å-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ —Ç–æ—á–µ–∫ —Ä–æ—Å—Ç–∞ —á–µ—Ä–µ–∑ –¥–∞–Ω–Ω—ã–µ',
                'type': 'business_insights',
                'enable_gpt': True,
                'priority': 3
            },
            {
                'question': 'üîÆ –û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏',
                'type': 'predictive_analysis',
                'enable_gpt': True,
                'priority': 4
            },
            {
                'question': 'üí° –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–¥–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö',
                'type': 'business_insights',
                'enable_gpt': True,
                'priority': 4
            }
        ])

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    plan.sort(key=lambda x: x.get('priority', 5))
    return plan[:max_questions]


def _map_analysis_to_smartgpt_type(question: str, analysis_type: str) -> str:
    """–ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è SmartGPT"""
    mapping = {
        'overview': 'business_insights',
        'table_analysis': 'business_insights',
        'business_insights': 'business_insights',
        'data_quality': 'data_quality',
        'statistical_insights': 'statistical_insights',
        'correlation': 'statistical_insights',
        'trend_analysis': 'predictive_analysis',
        'predictive_analysis': 'predictive_analysis',
        'relationship_analysis': 'data_quality',
        'anomalies': 'data_quality',
        'comparison': 'business_insights'
    }
    return mapping.get(analysis_type, 'business_insights')


def _extract_user_intent(question: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤–æ–ø—Ä–æ—Å–∞"""
    question_lower = question.lower()

    if any(word in question_lower for word in ['–ø—Ä–æ–±–ª–µ–º', '–æ—à–∏–±–∫', '–∞–Ω–æ–º–∞–ª–∏', '–ø–ª–æ—Ö–æ']):
        return 'problem_solving'
    elif any(word in question_lower for word in ['–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç', '–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª', '—Ä–æ—Å—Ç', '—É–ª—É—á—à–µ–Ω']):
        return 'opportunity_discovery'
    elif any(word in question_lower for word in ['—Å—Ä–∞–≤–Ω', '—Ä–∞–∑–ª–∏—á', 'vs', '–ø—Ä–æ—Ç–∏–≤']):
        return 'comparative_analysis'
    elif any(word in question_lower for word in ['—Ç—Ä–µ–Ω–¥', '–¥–∏–Ω–∞–º–∏–∫', '–ø—Ä–æ–≥–Ω–æ–∑', '–±—É–¥—É—â']):
        return 'trend_analysis'
    elif any(word in question_lower for word in ['–æ–ø—Ç–∏–º–∏–∑', '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç', '–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç']):
        return 'optimization'
    else:
        return 'general_insights'


def _generate_smartgpt_recommendations(smartgpt_findings: List[dict], table_summary: dict,
                                       successful_analyses: int, gpt_insights_count: int) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SmartGPT —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""

    recommendations = []

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º SmartGPT —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    all_action_items = []
    all_opportunities = []
    high_confidence_insights = 0

    for finding in smartgpt_findings:
        smartgpt_data = finding.get('smartgpt_insights', {})
        if smartgpt_data:
            if smartgpt_data.get('action_items'):
                all_action_items.extend(smartgpt_data['action_items'])
            if smartgpt_data.get('opportunities'):
                all_opportunities.extend(smartgpt_data['opportunities'])
            if smartgpt_data.get('confidence') == 'high':
                high_confidence_insights += 1

    # SmartGPT —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if gpt_insights_count > 0:
        recommendations.append(
            f"ü§ñ –ü–æ–ª—É—á–µ–Ω–æ {gpt_insights_count} SmartGPT –∏–Ω—Å–∞–π—Ç–æ–≤ —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"
        )

        if high_confidence_insights > gpt_insights_count * 0.7:
            recommendations.append(
                "‚úÖ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö - SmartGPT –∏–Ω—Å–∞–π—Ç—ã –∏–º–µ—é—Ç –≤—ã—Å–æ–∫—É—é –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å"
            )

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    if all_action_items:
        unique_actions = list(set(all_action_items))[:3]
        recommendations.append(
            f"üéØ –í—ã—è–≤–ª–µ–Ω–æ {len(unique_actions)} –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è"
        )

    # –ë–∏–∑–Ω–µ—Å-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    if all_opportunities:
        unique_opportunities = list(set(all_opportunities))[:3]
        recommendations.append(
            f"üöÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(unique_opportunities)} –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è —Ä–æ—Å—Ç–∞ –±–∏–∑–Ω–µ—Å–∞"
        )

    # –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    success_rate = (successful_analyses / max(len(smartgpt_findings), 1)) * 100
    gpt_coverage = (gpt_insights_count / max(successful_analyses, 1)) * 100

    if success_rate > 85 and gpt_coverage > 70:
        recommendations.extend([
            "üîÑ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ SmartGPT –æ—Ç—á–µ—Ç—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞",
            "üìä –°–æ–∑–¥–∞–π—Ç–µ –¥–∞—à–±–æ—Ä–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö SmartGPT –º–µ—Ç—Ä–∏–∫",
            "üîî –í–Ω–µ–¥—Ä–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É –∞–ª–µ—Ä—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"
        ])

    # –†–∞–∑–≤–∏—Ç–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    total_memory = table_summary.get('total_memory_mb', 0)
    if total_memory > 1000:
        recommendations.append(
            "‚ö° –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –µ—â–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
        )

    recommendations.extend([
        "üé® –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ SmartGPT –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É",
        "üìà –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
        "ü§ù –ü–æ–¥–µ–ª–∏—Ç–µ—Å—å –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç–∞–º–∏ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏",
        "üîÆ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤"
    ])

    return recommendations[:10]


def _create_fallback_executive_summary(smartgpt_findings: List[dict], table_summary: dict,
                                       successful_analyses: int) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ executive summary"""

    total_questions = len(smartgpt_findings)
    total_tables = table_summary.get('total_tables', 0)
    total_relations = table_summary.get('total_relations', 0)

    return (
        f"–ó–∞–≤–µ—Ä—à–µ–Ω SmartGPT DataFrame-–∞–Ω–∞–ª–∏–∑ —Å {successful_analyses} —É—Å–ø–µ—à–Ω—ã–º–∏ –∞–Ω–∞–ª–∏–∑–∞–º–∏ "
        f"–∏–∑ {total_questions} –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {total_tables} —Ç–∞–±–ª–∏—Ü "
        f"—Å {total_relations} —Å–≤—è–∑—è–º–∏. SmartGPT –∏–Ω—Å–∞–π—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
    )


def _trim_smartgpt_report(report: dict) -> dict:
    """–°–æ–∫—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä SmartGPT –æ—Ç—á–µ—Ç–∞"""
    try:
        trimmed = report.copy()

        # –°–æ–∫—Ä–∞—â–∞–µ–º detailed_findings
        if 'detailed_findings' in trimmed and isinstance(trimmed['detailed_findings'], list):
            for finding in trimmed['detailed_findings']:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä data_preview
                if 'data_preview' in finding and isinstance(finding['data_preview'], list):
                    if len(finding['data_preview']) > 3:
                        finding['data_preview'] = finding['data_preview'][:3]
                        finding['data_preview'].append({"note": "... –¥–∞–Ω–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞"})

                # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ SmartGPT –∏–Ω—Å–∞–π—Ç—ã
                smartgpt_insights = finding.get('smartgpt_insights', {})
                if smartgpt_insights.get('business_insights') and len(smartgpt_insights['business_insights']) > 800:
                    smartgpt_insights['business_insights'] = smartgpt_insights['business_insights'][
                                                             :800] + "... (—Å–æ–∫—Ä–∞—â–µ–Ω–æ)"

        trimmed['report_metadata']['trimmed'] = True
        trimmed['report_metadata']['trim_reason'] = "SmartGPT –æ—Ç—á–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞"

        return trimmed

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è SmartGPT –æ—Ç—á–µ—Ç–∞: {e}")
        return report


# =============== –°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ó–ê–î–ê–ß–ò ===============

@celery_app.task(bind=True, time_limit=3600, name='tasks.quick_dataframe_analysis')
def quick_dataframe_analysis(self, connection_id: int, user_id: int, report_id: int):
    """–ë—ã—Å—Ç—Ä—ã–π SmartGPT –∞–Ω–∞–ª–∏–∑ (8 –≤–æ–ø—Ä–æ—Å–æ–≤, ~10 –º–∏–Ω—É—Ç)"""
    logger.info(f"[QUICK SMARTGPT] ‚ö° –ó–∞–ø—É—Å–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    return generate_dataframe_report.apply_async(
        args=[connection_id, user_id, report_id],
        kwargs={'max_questions': 8}
    ).get()


@celery_app.task(bind=True, time_limit=9000, name='tasks.comprehensive_dataframe_analysis')
def comprehensive_dataframe_analysis(self, connection_id: int, user_id: int, report_id: int):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π SmartGPT –∞–Ω–∞–ª–∏–∑ (25 –≤–æ–ø—Ä–æ—Å–æ–≤, ~45 –º–∏–Ω—É—Ç)"""
    logger.info(f"[COMPREHENSIVE SMARTGPT] üß† –ó–∞–ø—É—Å–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    return generate_dataframe_report.apply_async(
        args=[connection_id, user_id, report_id],
        kwargs={'max_questions': 25}
    ).get()


# =============== LEGACY –ü–û–î–î–ï–†–ñ–ö–ê ===============

@celery_app.task(bind=True, time_limit=7200, name='tasks.generate_advanced_report')
def generate_advanced_report(self, connection_id: int, user_id: int, report_id: int):
    """Legacy —Ñ—É–Ω–∫—Ü–∏—è - –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞ SmartGPT –∞–Ω–∞–ª–∏–∑"""
    logger.warning(f"[LEGACY] ‚ö†Ô∏è –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ SmartGPT –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    return generate_dataframe_report.apply_async(
        args=[connection_id, user_id, report_id],
        kwargs={'max_questions': 15}
    ).get()


logger.info("üöÄ SmartGPT DataFrame Tasks —Å–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
