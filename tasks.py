# tasks.py - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ SmartGPTAnalyzer

import logging
from typing import List, Dict, Any
import numpy as np
from celery.exceptions import Ignore
from sqlalchemy import create_engine, text
import crud
import database
from services.dataframe_manager import DataFrameManager
from services.dataframe_analyzer import DataFrameAnalyzer
from services.smart_gpt_analyzer import SmartGPTAnalyzer  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç
from utils.json_serializer import convert_to_serializable
from celery_worker import celery_app
from datetime import datetime, timedelta
import json
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ utils
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logger = logging.getLogger(__name__)


@celery_app.task(bind=True, time_limit=7200, name='tasks.generate_smart_dataframe_report')
def generate_smart_dataframe_report(self, connection_id: int, user_id: int, report_id: int, max_questions: int = 15):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ —Å SmartGPT –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π - –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    """
    db_session = next(database.get_db())

    try:
        logger.info(f"[SMART DATAFRAME] –ó–∞–ø—É—Å–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, –æ—Ç—á–µ—Ç {report_id}")

        # === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===
        self.update_state(
            state='INITIALIZING',
            meta={'progress': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SmartGPT DataFrame —Å–∏—Å—Ç–µ–º—ã...'}
        )

        connection_string = crud.get_decrypted_connection_string(db_session, connection_id, user_id)
        if not connection_string:
            raise ValueError("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")

        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        engine = create_engine(connection_string, connect_args={'connect_timeout': 60})

        # === –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
        self.update_state(
            state='LOADING_DATA',
            meta={'progress': '–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∞–±–ª–∏—Ü —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π...', 'progress_percentage': 10}
        )

        df_manager = DataFrameManager(engine)
        tables_loaded = df_manager.load_all_tables(max_rows_per_table=50000)

        if not tables_loaded:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã")

        logger.info(f"[SMART DATAFRAME] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(tables_loaded)} —Ç–∞–±–ª–∏—Ü")

        # === –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ò –°–û–ó–î–ê–ù–ò–ï –ê–ù–ê–õ–ò–ó–ê–¢–û–†–û–í ===
        self.update_state(
            state='OPTIMIZING',
            meta={'progress': '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SmartGPT...', 'progress_percentage': 20}
        )

        df_manager.optimize_memory()
        analyzer = DataFrameAnalyzer(df_manager)
        smart_gpt = SmartGPTAnalyzer()

        # === –°–û–ó–î–ê–ù–ò–ï –£–ú–ù–û–ì–û –ü–õ–ê–ù–ê –ê–ù–ê–õ–ò–ó–ê ===
        self.update_state(
            state='PLANNING',
            meta={'progress': '–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Å GPT –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π...', 'progress_percentage': 25}
        )

        analysis_plan = _create_smart_analysis_plan(df_manager, max_questions)
        logger.info(f"[SMART DATAFRAME] –ü–ª–∞–Ω: {len(analysis_plan)} —É–º–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")

        # === –í–´–ü–û–õ–ù–ï–ù–ò–ï –£–ú–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê ===
        smart_findings = []
        successful_analyses = 0
        gpt_insights_count = 0

        for i, question_config in enumerate(analysis_plan):
            if i >= max_questions:
                break

            progress = 25 + (i + 1) / min(len(analysis_plan), max_questions) * 60  # 25-85%
            question = question_config.get('question', str(question_config))
            analysis_type = question_config.get('type', 'general')

            self.update_state(
                state='SMART_ANALYZING',
                meta={
                    'progress': f'SmartGPT –∞–Ω–∞–ª–∏–∑ {i + 1}/{min(len(analysis_plan), max_questions)}: {question[:50]}...',
                    'progress_percentage': progress,
                    'analysis_type': analysis_type
                }
            )

            logger.info(f"[SMART DATAFRAME] –ê–Ω–∞–ª–∏–∑ {i + 1}: {question} (—Ç–∏–ø: {analysis_type})")

            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º DataFrame –∞–Ω–∞–ª–∏–∑ —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º SmartGPT
                result = analyzer.analyze_question(question)

                if not result.get('error'):
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
                    data_preview = result.get('data', [])
                    if hasattr(data_preview, 'head'):
                        data_preview = convert_to_serializable(data_preview.head(10).to_dict('records'))
                    elif isinstance(data_preview, (list, dict)):
                        data_preview = convert_to_serializable(data_preview)
                    else:
                        data_preview = []

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º SmartGPT –∏–Ω—Å–∞–π—Ç—ã
                    smart_insights = result.get('smart_gpt_insights', {})
                    has_smart_insights = bool(smart_insights.get('business_insights'))

                    if has_smart_insights:
                        gpt_insights_count += 1

                    # –°–æ–∑–¥–∞–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                    finding_entry = {
                        'question': str(question),
                        'summary': str(result.get('summary', '')),
                        'data_preview': data_preview[:10],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                        'chart_data': convert_to_serializable(result.get('chart_data')),
                        'analyzed_tables': list(result.get('analyzed_tables', [])),
                        'method': 'smart_dataframe_gpt',
                        'analysis_type': analysis_type,

                        # SmartGPT –¥–∞–Ω–Ω—ã–µ
                        'business_insights': smart_insights.get('business_insights', ''),
                        'action_items': smart_insights.get('action_items', []),
                        'risk_assessment': smart_insights.get('risk_assessment', ''),
                        'opportunities': smart_insights.get('opportunities', []),
                        'gpt_confidence': smart_insights.get('confidence', 'medium'),
                        'business_context': smart_insights.get('business_context', {}),

                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        'statistical_insights': convert_to_serializable(result.get('statistical_insights', [])),
                        'correlations': convert_to_serializable(result.get('correlations', [])),
                        'quality_metrics': convert_to_serializable(result.get('quality_metrics', [])),
                        'predictive_patterns': convert_to_serializable(result.get('predictive_patterns', [])),

                        'timestamp': datetime.now().isoformat(),
                        'success': True,
                        'has_smart_insights': has_smart_insights
                    }

                    smart_findings.append(finding_entry)
                    successful_analyses += 1

                    logger.info(f"[SMART DATAFRAME] ‚úÖ –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {i + 1} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")

                else:
                    error_msg = str(result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'))
                    logger.error(f"[SMART DATAFRAME] ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {i + 1}: {error_msg}")

                    smart_findings.append({
                        'question': str(question),
                        'summary': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_msg}',
                        'data_preview': [],
                        'error': error_msg,
                        'method': 'smart_dataframe_gpt',
                        'analysis_type': analysis_type,
                        'success': False,
                        'timestamp': datetime.now().isoformat(),
                        'has_smart_insights': False
                    })

            except Exception as analysis_error:
                error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —É–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(analysis_error)}"
                logger.error(f"[SMART DATAFRAME] üí• {error_msg}")

                smart_findings.append({
                    'question': str(question),
                    'summary': error_msg,
                    'data_preview': [],
                    'error': error_msg,
                    'method': 'smart_dataframe_gpt',
                    'analysis_type': analysis_type,
                    'success': False,
                    'timestamp': datetime.now().isoformat(),
                    'has_smart_insights': False
                })

        # === –°–û–ó–î–ê–ù–ò–ï –£–ú–ù–û–ì–û EXECUTIVE SUMMARY ===
        self.update_state(
            state='GENERATING_SUMMARY',
            meta={'progress': '–°–æ–∑–¥–∞–Ω–∏–µ —É–º–Ω–æ–≥–æ executive summary...', 'progress_percentage': 85}
        )

        logger.info(
            f"[SMART DATAFRAME] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {successful_analyses}/{len(smart_findings)} —É—Å–ø–µ—à–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤, {gpt_insights_count} SmartGPT –∏–Ω—Å–∞–π—Ç–æ–≤")

        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
        table_summary = df_manager.get_table_summary()
        memory_info = df_manager.get_memory_usage()

        # === –£–ú–ù–´–ô EXECUTIVE SUMMARY ===
        executive_summary = ""
        try:
            if successful_analyses > 0 and gpt_insights_count > 0:
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –º–µ—Ç–∞—Å–≤–æ–¥–∫–∏
                business_insights = []
                all_action_items = []
                all_risks = []
                all_opportunities = []

                for finding in smart_findings:
                    if finding.get('has_smart_insights'):
                        if finding.get('business_insights'):
                            business_insights.append(finding['business_insights'])
                        if finding.get('action_items'):
                            all_action_items.extend(finding['action_items'])
                        if finding.get('risk_assessment'):
                            all_risks.append(finding['risk_assessment'])
                        if finding.get('opportunities'):
                            all_opportunities.extend(finding['opportunities'])

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ—Ç–∞—Å–≤–æ–¥–∫—É —á–µ—Ä–µ–∑ SmartGPT
                executive_summary = smart_gpt.generate_executive_summary_smart(
                    smart_findings, table_summary
                )

            else:
                executive_summary = _create_fallback_executive_summary(
                    smart_findings, table_summary, successful_analyses
                )

        except Exception as summary_error:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —É–º–Ω–æ–π —Å–≤–æ–¥–∫–∏: {summary_error}")
            executive_summary = _create_fallback_executive_summary(
                smart_findings, table_summary, successful_analyses
            )

        # === –°–û–ó–î–ê–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ì–û –£–ú–ù–û–ì–û –û–¢–ß–ï–¢–ê ===
        self.update_state(
            state='FINALIZING',
            meta={'progress': '–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...', 'progress_percentage': 90}
        )

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å SmartGPT –¥–∞–Ω–Ω—ã–º–∏
        final_report = {
            "executive_summary": str(executive_summary),
            "detailed_findings": convert_to_serializable(smart_findings),
            "method": "smart_dataframe_gpt_v2",
            "tables_info": convert_to_serializable(table_summary['tables']),
            "relations_info": convert_to_serializable(table_summary['relations']),

            "smart_analysis_stats": {
                "questions_processed": int(len(smart_findings)),
                "successful_analyses": int(successful_analyses),
                "failed_analyses": int(len(smart_findings) - successful_analyses),
                "smart_gpt_insights_count": int(gpt_insights_count),
                "tables_analyzed": int(table_summary['total_tables']),
                "relations_found": int(table_summary['total_relations']),
                "total_memory_mb": round(float(table_summary['total_memory_mb']), 2),
                "success_rate_percent": round(float(successful_analyses / max(len(smart_findings), 1) * 100), 1),
                "smart_gpt_coverage_percent": round(float(gpt_insights_count / max(successful_analyses, 1) * 100), 1)
            },

            "memory_usage": convert_to_serializable(memory_info),
            "smart_recommendations": [str(r) for r in _generate_smart_recommendations(
                smart_findings, table_summary, successful_analyses, gpt_insights_count
            )],

            "report_metadata": {
                "created_at": datetime.now().isoformat(),
                "user_id": int(user_id),
                "connection_id": int(connection_id),
                "report_version": "4.0_smart_dataframe_gpt",
                "max_questions_requested": int(max_questions),
                "smart_gpt_enabled": True,
                "analysis_engine": "SmartGPTAnalyzer"
            }
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ—Ç—á–µ—Ç–∞
        try:
            report_json = json.dumps(final_report, ensure_ascii=False)
            report_size_mb = len(report_json.encode('utf-8')) / 1024 / 1024
            logger.info(f"[SMART DATAFRAME] –†–∞–∑–º–µ—Ä —É–º–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {report_size_mb:.2f} MB")

            if report_size_mb > 15:  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è —É–º–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
                logger.warning(f"[SMART DATAFRAME] –û—Ç—á–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({report_size_mb:.2f} MB), —Å–æ–∫—Ä–∞—â–∞–µ–º")
                final_report = _trim_smart_report(final_report)

        except Exception as json_error:
            logger.error(f"[SMART DATAFRAME] –û—à–∏–±–∫–∞ JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {json_error}")
            final_report = convert_to_serializable(final_report)

        # === –°–û–•–†–ê–ù–ï–ù–ò–ï –£–ú–ù–û–ì–û –û–¢–ß–ï–¢–ê ===
        self.update_state(
            state='SAVING',
            meta={'progress': '–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É–º–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...', 'progress_percentage': 95}
        )

        try:
            crud.update_report(db_session, report_id, "COMPLETED", final_report)
            logger.info(f"[SMART DATAFRAME] ‚úÖ –£–º–Ω—ã–π –æ—Ç—á–µ—Ç {report_id} —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")

        except Exception as save_error:
            logger.error(f"[SMART DATAFRAME] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {save_error}")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            simplified_report = {
                "executive_summary": final_report["executive_summary"],
                "method": "smart_dataframe_gpt_v2",
                "smart_analysis_stats": final_report["smart_analysis_stats"],
                "error": f"–ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {str(save_error)}",
                "report_metadata": final_report["report_metadata"]
            }
            crud.update_report(db_session, report_id, "COMPLETED", simplified_report)

        self.update_state(
            state='SUCCESS',
            meta={'progress': 'SmartGPT DataFrame-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!', 'progress_percentage': 100}
        )

        return {
            "status": "success",
            "report_id": report_id,
            "questions_processed": len(smart_findings),
            "successful_analyses": successful_analyses,
            "smart_gpt_insights": gpt_insights_count,
            "tables_loaded": len(tables_loaded),
            "method": "smart_dataframe_gpt_v2"
        }

    except Exception as e:
        logger.error(f"[SMART DATAFRAME ERROR] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
        error_report = {
            "error": str(e),
            "method": "smart_dataframe_gpt_v2",
            "stage": "critical_error",
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "connection_id": connection_id
        }

        try:
            crud.update_report(db_session, report_id, "FAILED", error_report)
        except Exception as save_error:
            logger.error(f"[SMART DATAFRAME] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—à–∏–±–∫—É: {save_error}")

        self.update_state(
            state='FAILURE',
            meta={
                'progress': f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ SmartGPT: {str(e)}',
                'error': str(e),
                'progress_percentage': 0
            }
        )

        raise e

    finally:
        try:
            db_session.close()
        except:
            pass


def _create_smart_analysis_plan(df_manager: DataFrameManager, max_questions: int) -> List[Dict[str, Any]]:
    """–°–æ–∑–¥–∞–µ—Ç —É–º–Ω—ã–π –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è SmartGPT"""

    plan = [
        {
            'question': '–£–º–Ω—ã–π –æ–±–∑–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏',
            'type': 'overview',
            'enable_smart_gpt': True,
            'priority': 1
        }
    ]

    # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π –≤–∞–∂–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å SmartGPT –∏–Ω—Å–∞–π—Ç–∞–º–∏
    tables_by_size = sorted(df_manager.tables.items(), key=lambda x: len(x[1]), reverse=True)

    for i, (table_name, df) in enumerate(tables_by_size[:min(3, len(tables_by_size))]):
        plan.extend([
            {
                'question': f"–£–º–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã '{table_name}' —Å –≤—ã—è–≤–ª–µ–Ω–∏–µ–º —Å–∫—Ä—ã—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π",
                'type': 'business_insights',
                'table_focus': table_name,
                'enable_smart_gpt': True,
                'priority': 1 if i == 0 else 2
            },
            {
                'question': f"–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü—ã '{table_name}' —Å —É–º–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏",
                'type': 'data_quality',
                'table_focus': table_name,
                'enable_smart_gpt': True,
                'priority': 2
            }
        ])

    # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SmartGPT –∞–Ω–∞–ª–∏–∑—ã
    has_numeric_data = any(
        len(df.select_dtypes(include=[np.number]).columns) > 0
        for df in df_manager.tables.values()
    )

    has_datetime_data = any(
        any('date' in col.lower() or 'time' in col.lower() for col in df.columns)
        for df in df_manager.tables.values()
    )

    if has_numeric_data:
        plan.extend([
            {
                'question': '–£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å SmartGPT –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–µ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤',
                'type': 'statistical_insights',
                'enable_smart_gpt': True,
                'priority': 2
            },
            {
                'question': '–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å –±–∏–∑–Ω–µ—Å-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–µ–π –∏ –≤—ã–≤–æ–¥–∞–º–∏',
                'type': 'correlation',
                'enable_smart_gpt': True,
                'priority': 2
            }
        ])

    if has_datetime_data:
        plan.extend([
            {
                'question': '–£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏',
                'type': 'predictive_analysis',
                'enable_smart_gpt': True,
                'priority': 2
            }
        ])

    # –°–≤—è–∑–∏ –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∞–º–∏
    if df_manager.relations:
        plan.append({
            'question': '–ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Å–≤—è–∑–µ–π —Å —É–º–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏',
            'type': 'relationship_analysis',
            'enable_smart_gpt': True,
            'priority': 2
        })

    # –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    plan.extend([
        {
            'question': '–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø—Ä–∏—á–∏–Ω –∏ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –±–∏–∑–Ω–µ—Å',
            'type': 'anomalies',
            'enable_smart_gpt': True,
            'priority': 3
        },
        {
            'question': '–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü —Å –≤—ã—è–≤–ª–µ–Ω–∏–µ–º —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤',
            'type': 'comparison',
            'enable_smart_gpt': True,
            'priority': 3
        }
    ])

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–ª–∞–Ω–æ–≤
    if max_questions > 15:
        plan.extend([
            {
                'question': '–ü–æ–∏—Å–∫ —Å–∫—Ä—ã—Ç—ã—Ö –±–∏–∑–Ω–µ—Å-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ —Ç–æ—á–µ–∫ —Ä–æ—Å—Ç–∞ —á–µ—Ä–µ–∑ –¥–∞–Ω–Ω—ã–µ',
                'type': 'business_insights',
                'enable_smart_gpt': True,
                'priority': 3
            },
            {
                'question': '–û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏',
                'type': 'predictive_analysis',
                'enable_smart_gpt': True,
                'priority': 4
            }
        ])

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    plan.sort(key=lambda x: x.get('priority', 5))
    return plan[:max_questions]


def _generate_smart_recommendations(smart_findings: List[dict], table_summary: dict,
                                    successful_analyses: int, gpt_insights_count: int) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ SmartGPT –∏–Ω—Å–∞–π—Ç–æ–≤"""

    recommendations = []

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º SmartGPT –∏–Ω—Å–∞–π—Ç—ã
    all_action_items = []
    all_opportunities = []
    high_confidence_insights = 0

    for finding in smart_findings:
        if finding.get('has_smart_insights'):
            if finding.get('action_items'):
                all_action_items.extend(finding['action_items'])
            if finding.get('opportunities'):
                all_opportunities.extend(finding['opportunities'])
            if finding.get('gpt_confidence') == 'high':
                high_confidence_insights += 1

    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ SmartGPT
    if gpt_insights_count > 0:
        recommendations.append(
            f"ü§ñ –ü–æ–ª—É—á–µ–Ω–æ {gpt_insights_count} —É–º–Ω—ã—Ö GPT-–∏–Ω—Å–∞–π—Ç–æ–≤ —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"
        )

        if high_confidence_insights > gpt_insights_count * 0.7:
            recommendations.append(
                "‚úÖ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö - GPT-–∏–Ω—Å–∞–π—Ç—ã –∏–º–µ—é—Ç –≤—ã—Å–æ–∫—É—é –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å"
            )

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    if all_action_items:
        top_actions = list(set(all_action_items))[:3]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–æ–ø-3
        recommendations.append(
            f"üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –≤—ã—è–≤–ª–µ–Ω—ã: {len(top_actions)} –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
        )

    # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞
    if all_opportunities:
        unique_opportunities = list(set(all_opportunities))[:3]
        recommendations.append(
            f"üöÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(unique_opportunities)} –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è —Ä–æ—Å—Ç–∞ –±–∏–∑–Ω–µ—Å–∞"
        )

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
    success_rate = (successful_analyses / max(len(smart_findings), 1)) * 100
    gpt_coverage = (gpt_insights_count / max(successful_analyses, 1)) * 100

    if success_rate > 85 and gpt_coverage > 70:
        recommendations.extend([
            "üîÑ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ SmartGPT –æ—Ç—á–µ—Ç—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞",
            "üìä –°–æ–∑–¥–∞–π—Ç–µ –¥–∞—à–±–æ—Ä–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫",
            "üîî –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∞–ª–µ—Ä—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤"
        ])

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω—ã–º
    total_memory = table_summary.get('total_memory_mb', 0)
    if total_memory > 1000:
        recommendations.append(
            "‚ö° –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö - –±–æ–ª—å—à–æ–π –æ–±—ä–µ–º –≤ –ø–∞–º—è—Ç–∏"
        )

    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations.extend([
        "üé® –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ —Å—Ç–µ–π–∫—Ö–æ–ª–¥–µ—Ä–∞–º",
        "üìà –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
        "ü§ù –ü–æ–¥–µ–ª–∏—Ç–µ—Å—å –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç–∞–º–∏ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏"
    ])

    return recommendations[:8]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ


def _create_fallback_executive_summary(smart_findings: List[dict], table_summary: dict,
                                       successful_analyses: int) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ executive summary –µ—Å–ª–∏ SmartGPT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""

    total_questions = len(smart_findings)
    total_tables = table_summary.get('total_tables', 0)
    total_relations = table_summary.get('total_relations', 0)

    return (
        f"–ó–∞–≤–µ—Ä—à–µ–Ω —É–º–Ω—ã–π DataFrame-–∞–Ω–∞–ª–∏–∑ —Å {successful_analyses} —É—Å–ø–µ—à–Ω—ã–º–∏ –∞–Ω–∞–ª–∏–∑–∞–º–∏ "
        f"–∏–∑ {total_questions} –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {total_tables} —Ç–∞–±–ª–∏—Ü "
        f"—Å {total_relations} —Å–≤—è–∑—è–º–∏. SmartGPT –∏–Ω—Å–∞–π—Ç—ã —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è..."
    )


def _trim_smart_report(report: dict) -> dict:
    """–°–æ–∫—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —É–º–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    try:
        trimmed = report.copy()

        # –°–æ–∫—Ä–∞—â–∞–µ–º detailed_findings
        if 'detailed_findings' in trimmed and isinstance(trimmed['detailed_findings'], list):
            for finding in trimmed['detailed_findings']:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä data_preview
                if 'data_preview' in finding and isinstance(finding['data_preview'], list):
                    if len(finding['data_preview']) > 3:
                        finding['data_preview'] = finding['data_preview'][:3]
                        finding['data_preview'].append({"note": "... –¥–∞–Ω–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω—ã"})

                # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã
                for text_field in ['business_insights', 'risk_assessment']:
                    if finding.get(text_field) and len(finding[text_field]) > 800:
                        finding[text_field] = finding[text_field][:800] + "... (—Å–æ–∫—Ä–∞—â–µ–Ω–æ)"

        trimmed['report_metadata']['trimmed'] = True
        trimmed['report_metadata']['trim_reason'] = "–û—Ç—á–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞"

        return trimmed

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —É–º–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
        return report


# –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ - –±—ã—Å—Ç—Ä—ã–π –∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
@celery_app.task(bind=True, time_limit=3600, name='tasks.quick_smart_analysis')
def quick_smart_analysis(self, connection_id: int, user_id: int, report_id: int):
    """–ë—ã—Å—Ç—Ä—ã–π SmartGPT –∞–Ω–∞–ª–∏–∑"""
    logger.info(f"[QUICK SMART] –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ SmartGPT –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    return generate_smart_dataframe_report.apply_async(
        args=[connection_id, user_id, report_id],
        kwargs={'max_questions': 8}
    ).get()


@celery_app.task(bind=True, time_limit=9000, name='tasks.comprehensive_smart_analysis')
def comprehensive_smart_analysis(self, connection_id: int, user_id: int, report_id: int):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π SmartGPT –∞–Ω–∞–ª–∏–∑"""
    logger.info(f"[COMPREHENSIVE SMART] –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ SmartGPT –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    return generate_smart_dataframe_report.apply_async(
        args=[connection_id, user_id, report_id],
        kwargs={'max_questions': 25}
    ).get()


# Legacy —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
@celery_app.task(bind=True, time_limit=7200, name='tasks.generate_dataframe_report')
def generate_dataframe_report(self, connection_id: int, user_id: int, report_id: int, max_questions: int = 15):
    """Legacy —Ñ—É–Ω–∫—Ü–∏—è - –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞ SmartGPT –∞–Ω–∞–ª–∏–∑"""
    logger.warning(f"[LEGACY] –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ SmartGPT –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    return generate_smart_dataframe_report.apply_async(
        args=[connection_id, user_id, report_id],
        kwargs={'max_questions': max_questions}
    ).get()


logger.info("SmartGPT DataFrame tasks —Å–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
