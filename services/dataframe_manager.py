# services/dataframe_manager.py
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import logging
from sqlalchemy import inspect, text
import numpy as np
import sys
import os

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.json_serializer import convert_to_serializable, clean_dataframe_for_json

logger = logging.getLogger(__name__)


@dataclass
class TableRelation:
    """ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""
    from_table: str
    to_table: str
    from_column: str
    to_column: str
    relation_type: str  # one_to_many, many_to_many, one_to_one


class DataFrameManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ DataFrame"""

    def __init__(self, engine):
        self.engine = engine
        self.tables: Dict[str, pd.DataFrame] = {}
        self.relations: List[TableRelation] = []
        self.table_schemas: Dict[str, Dict] = {}
        self.total_memory_usage = 0.0

    def load_all_tables(self, max_rows_per_table: int = 100000) -> Dict[str, pd.DataFrame]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð²ÑÐµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð² Ð¿Ð°Ð¼ÑÑ‚ÑŒ ÐºÐ°Ðº DataFrame"""
        inspector = inspect(self.engine)
        tables_loaded = 0

        logger.info("ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð²ÑÐµÑ… Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ð² DataFrame...")

        for table_name in inspector.get_table_names():
            if table_name in ['alembic_version', 'django_migrations', 'schema_migrations']:
                continue

            try:
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
                with self.engine.connect() as conn:
                    count_result = conn.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
                    row_count = count_result.scalar()

                if row_count == 0:
                    logger.info(f"ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÑÑ‚ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ {table_name}")
                    continue

                # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ‚Ñ€Ð¾Ðº Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ñ‚Ð°Ð±Ð»Ð¸Ñ†
                if row_count > max_rows_per_table:
                    logger.warning(
                        f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° {table_name} ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ {row_count} ÑÑ‚Ñ€Ð¾Ðº, Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ {max_rows_per_table}")
                    query = f"SELECT * FROM {table_name} LIMIT {max_rows_per_table}"
                else:
                    query = f"SELECT * FROM {table_name}"

                # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
                df = pd.read_sql(query, self.engine)

                if not df.empty:
                    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
                    df = self._clean_dataframe(df)

                    self.tables[table_name] = df

                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑ…ÐµÐ¼Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
                    columns = inspector.get_columns(table_name)
                    primary_keys = []
                    try:
                        pk_constraint = inspector.get_pk_constraint(table_name)
                        primary_keys = pk_constraint.get('constrained_columns', []) if pk_constraint else []
                    except:
                        primary_keys = []

                    memory_mb = df.memory_usage(deep=True).sum() / 1024 / 1024

                    self.table_schemas[table_name] = {
                        'columns': {col['name']: str(col['type']) for col in columns},
                        'row_count': len(df),
                        'total_row_count': int(row_count),
                        'primary_keys': primary_keys,
                        'memory_usage_mb': round(memory_mb, 3),
                        'is_truncated': row_count > max_rows_per_table
                    }

                    tables_loaded += 1
                    self.total_memory_usage += memory_mb

                    logger.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° {table_name}: {len(df)}/{row_count} ÑÑ‚Ñ€Ð¾Ðº, {memory_mb:.2f} MB")

            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {table_name}: {e}")

        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸
        self._discover_relations(inspector)

        logger.info(f"ðŸŽ‰ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {tables_loaded} Ñ‚Ð°Ð±Ð»Ð¸Ñ†, {len(self.relations)} ÑÐ²ÑÐ·ÐµÐ¹, "
                    f"Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¾Ð±ÑŠÐµÐ¼: {self.total_memory_usage:.2f} MB")

        return self.tables

    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """ÐžÑ‡Ð¸Ñ‰Ð°ÐµÑ‚ DataFrame Ð¾Ñ‚ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹"""
        try:
            df_clean = df.copy()

            # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ inf Ð½Ð° NaN
            df_clean = df_clean.replace([np.inf, -np.inf], np.nan)

            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            for col in df_clean.columns:
                if df_clean[col].dtype == 'object':
                    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ None Ð² Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð´Ð»Ñ Ð¾Ð±ÑŠÐµÐºÑ‚Ð½Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
                    df_clean[col] = df_clean[col].astype(str).replace('None', '').replace('nan', '')
                elif pd.api.types.is_numeric_dtype(df_clean[col]):
                    # Ð”Ð»Ñ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ NaN Ð½Ð° 0 ÐµÑÐ»Ð¸ Ð¼Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ¾Ð²
                    null_pct = df_clean[col].isnull().sum() / len(df_clean)
                    if null_pct > 0.5:  # Ð•ÑÐ»Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐµ 50% Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ¾Ð²
                        df_clean[col] = df_clean[col].fillna(0)
                elif df_clean[col].dtype.kind in ['M', 'm']:  # datetime/timedelta
                    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ datetime Ð² ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð´Ð»Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸
                    try:
                        df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')
                        df_clean[col + '_str'] = df_clean[col].dt.strftime('%Y-%m-%d %H:%M:%S')
                    except:
                        pass

            return df_clean

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ DataFrame: {e}")
            return df

    def _discover_relations(self, inspector):
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ð²Ð°ÐµÑ‚ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""
        relations_found = 0

        for table_name in self.tables.keys():
            try:
                foreign_keys = inspector.get_foreign_keys(table_name)
                for fk in foreign_keys:
                    referred_table = fk.get('referred_table')
                    if referred_table and referred_table in self.tables:
                        constrained_columns = fk.get('constrained_columns', [])
                        referred_columns = fk.get('referred_columns', [])

                        if constrained_columns and referred_columns:
                            relation = TableRelation(
                                from_table=table_name,
                                to_table=referred_table,
                                from_column=constrained_columns[0],
                                to_column=referred_columns[0],
                                relation_type='many_to_one'
                            )
                            self.relations.append(relation)
                            relations_found += 1

            except Exception as e:
                logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ FK Ð´Ð»Ñ {table_name}: {e}")

        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº ÑÐ²ÑÐ·ÐµÐ¹ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð°Ð¼ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
        self._discover_implicit_relations()

        logger.info(f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(self.relations)} ÑÐ²ÑÐ·ÐµÐ¹ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸")

    def _discover_implicit_relations(self):
        """ÐŸÐ¾Ð¸ÑÐº Ð½ÐµÑÐ²Ð½Ñ‹Ñ… ÑÐ²ÑÐ·ÐµÐ¹ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð°Ð¼ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº"""
        table_names = list(self.tables.keys())

        for i, table1 in enumerate(table_names):
            for table2 in table_names[i + 1:]:
                df1 = self.tables[table1]
                df2 = self.tables[table2]

                # Ð˜Ñ‰ÐµÐ¼ Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ ÑÐ²ÑÐ·ÑÐ¼Ð¸
                common_columns = set(df1.columns).intersection(set(df2.columns))

                for col in common_columns:
                    if col.lower().endswith('_id') or col.lower() == 'id':
                        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ñ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
                        try:
                            values1 = set(df1[col].dropna().astype(str))
                            values2 = set(df2[col].dropna().astype(str))

                            if len(values1.intersection(values2)) > 0:
                                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ð¹ ÑÐ²ÑÐ·Ð¸ ÐµÑ‰Ðµ Ð½ÐµÑ‚
                                existing = any(
                                    (r.from_table == table1 and r.to_table == table2 and r.from_column == col) or
                                    (r.from_table == table2 and r.to_table == table1 and r.to_column == col)
                                    for r in self.relations
                                )

                                if not existing:
                                    relation = TableRelation(
                                        from_table=table1,
                                        to_table=table2,
                                        from_column=col,
                                        to_column=col,
                                        relation_type='implicit'
                                    )
                                    self.relations.append(relation)
                        except:
                            continue

    def join_tables(self, left_table: str, right_table: str,
                    join_type: str = 'inner', on: Optional[Dict[str, str]] = None) -> pd.DataFrame:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ JOIN Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""

        if left_table not in self.tables or right_table not in self.tables:
            raise ValueError(f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ñ‹ {left_table} Ð¸Ð»Ð¸ {right_table} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹")

        left_df = self.tables[left_table].copy()
        right_df = self.tables[right_table].copy()

        # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑÐ²ÑÐ·ÑŒ ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð°
        if on is None:
            relation = self._find_relation(left_table, right_table)
            if relation:
                on = {relation.from_column: relation.to_column}
            else:
                # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
                common_cols = set(left_df.columns).intersection(set(right_df.columns))
                if common_cols:
                    # ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ ID ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼
                    id_cols = [col for col in common_cols if 'id' in col.lower()]
                    common_col = id_cols[0] if id_cols else list(common_cols)[0]
                    on = {common_col: common_col}
                else:
                    raise ValueError(f"Ð¡Ð²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ {left_table} Ð¸ {right_table} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

        try:
            # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ JOIN
            result = pd.merge(
                left_df, right_df,
                left_on=list(on.keys()),
                right_on=list(on.values()),
                how=join_type,
                suffixes=('_left', '_right')
            )

            logger.info(f"JOIN Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½: {left_table} {join_type} {right_table} Ð½Ð° {on}, "
                        f"Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {len(result)} ÑÑ‚Ñ€Ð¾Ðº")

            return result

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° JOIN: {e}")
            raise

    def _find_relation(self, table1: str, table2: str) -> Optional[TableRelation]:
        """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÐ²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ Ð´Ð²ÑƒÐ¼Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""
        # ÐŸÑ€ÑÐ¼Ð°Ñ ÑÐ²ÑÐ·ÑŒ
        for relation in self.relations:
            if relation.from_table == table1 and relation.to_table == table2:
                return relation

        # ÐžÐ±Ñ€Ð°Ñ‚Ð½Ð°Ñ ÑÐ²ÑÐ·ÑŒ
        for relation in self.relations:
            if relation.from_table == table2 and relation.to_table == table1:
                return TableRelation(
                    from_table=table1,
                    to_table=table2,
                    from_column=relation.to_column,
                    to_column=relation.from_column,
                    relation_type=relation.relation_type
                )

        return None

    def complex_query(self, operations: List[Dict[str, Any]]) -> pd.DataFrame:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑÐ¼Ð¸"""
        result_df = None

        for i, op in enumerate(operations):
            op_type = op.get('type')
            logger.info(f"Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ {i + 1}: {op_type}")

            try:
                if op_type == 'select':
                    table_name = op['table']
                    columns = op.get('columns', None)

                    if table_name not in self.tables:
                        raise ValueError(f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° {table_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

                    result_df = self.tables[table_name].copy()

                    if columns:
                        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
                        missing_cols = [col for col in columns if col not in result_df.columns]
                        if missing_cols:
                            logger.warning(f"ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹: {missing_cols}")
                            columns = [col for col in columns if col in result_df.columns]

                        if columns:
                            result_df = result_df[columns]

                elif op_type == 'join':
                    if result_df is None:
                        raise ValueError("JOIN Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                    right_table = op['table']
                    join_type = op.get('how', 'inner')
                    on = op.get('on')

                    if right_table not in self.tables:
                        raise ValueError(f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° {right_table} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

                    right_df = self.tables[right_table]

                    if on:
                        result_df = pd.merge(
                            result_df, right_df,
                            left_on=on['left'],
                            right_on=on['right'],
                            how=join_type,
                            suffixes=('', '_right')
                        )
                    else:
                        # ÐÐ²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·Ð¸
                        common_cols = set(result_df.columns).intersection(set(right_df.columns))
                        if common_cols:
                            # ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ ID ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼
                            id_cols = [col for col in common_cols if 'id' in col.lower()]
                            common_col = id_cols[0] if id_cols else list(common_cols)[0]
                            result_df = pd.merge(
                                result_df, right_df,
                                on=common_col,
                                how=join_type,
                                suffixes=('', '_right')
                            )
                        else:
                            raise ValueError(f"ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð´Ð»Ñ JOIN Ñ {right_table}")

                elif op_type == 'filter':
                    if result_df is None:
                        raise ValueError("FILTER Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                    condition = op['condition']
                    try:
                        result_df = result_df.query(condition)
                    except Exception as filter_error:
                        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ '{condition}': {filter_error}")
                        # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ÑÑ‚ÑƒÑŽ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ
                        if 'column' in op and 'value' in op:
                            col = op['column']
                            val = op['value']
                            if col in result_df.columns:
                                result_df = result_df[result_df[col] == val]

                elif op_type == 'groupby':
                    if result_df is None:
                        raise ValueError("GROUPBY Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                    by = op['by']
                    agg_dict = op.get('agg', {})

                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¸
                    if isinstance(by, str):
                        by = [by]

                    existing_by = [col for col in by if col in result_df.columns]
                    if not existing_by:
                        logger.warning(f"ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹: {by}")
                        continue

                    # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÑƒ
                    if agg_dict:
                        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð´Ð»Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸
                        valid_agg = {k: v for k, v in agg_dict.items() if k in result_df.columns}
                        if valid_agg:
                            result_df = result_df.groupby(existing_by).agg(valid_agg).reset_index()
                    else:
                        # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° ÑÐ¾ ÑÑ‡ÐµÑ‚Ñ‡Ð¸ÐºÐ¾Ð¼
                        result_df = result_df.groupby(existing_by).size().reset_index(name='count')

                elif op_type == 'sort':
                    if result_df is None:
                        raise ValueError("SORT Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                    by = op['by']
                    ascending = op.get('ascending', True)

                    if isinstance(by, str):
                        by = [by]

                    existing_by = [col for col in by if col in result_df.columns]
                    if existing_by:
                        result_df = result_df.sort_values(existing_by, ascending=ascending)

                elif op_type == 'limit':
                    if result_df is None:
                        raise ValueError("LIMIT Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                    n = op['n']
                    result_df = result_df.head(n)

            except Exception as op_error:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ {op_type}: {op_error}")
                if result_df is None:
                    result_df = pd.DataFrame()
                continue

        if result_df is None:
            result_df = pd.DataFrame()

        logger.info(f"ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½, Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {len(result_df)} ÑÑ‚Ñ€Ð¾Ðº")
        return result_df

    def get_table_summary(self) -> Dict[str, Any]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¿Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼"""
        return {
            'total_tables': len(self.tables),
            'total_relations': len(self.relations),
            'total_memory_mb': round(self.total_memory_usage, 2),
            'tables': {
                name: {
                    'rows': len(df),
                    'columns': len(df.columns),
                    'memory_mb': round(df.memory_usage(deep=True).sum() / 1024 / 1024, 3),
                    'schema_info': self.table_schemas.get(name, {})
                }
                for name, df in self.tables.items()
            },
            'relations': [
                {
                    'from_table': rel.from_table,
                    'to_table': rel.to_table,
                    'from_column': rel.from_column,
                    'to_column': rel.to_column,
                    'type': rel.relation_type
                }
                for rel in self.relations
            ]
        }

    def get_memory_usage(self) -> Dict[str, float]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
        memory_info = {}

        for table_name, df in self.tables.items():
            memory_usage = df.memory_usage(deep=True)
            memory_info[table_name] = {
                'total_mb': round(memory_usage.sum() / 1024 / 1024, 3),
                'per_column_mb': {
                    col: round(usage / 1024 / 1024, 3)
                    for col, usage in memory_usage.items()
                }
            }

        return memory_info

    def optimize_memory(self):
        """ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
        for table_name, df in self.tables.items():
            try:
                original_size = df.memory_usage(deep=True).sum()

                # ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹
                for col in df.select_dtypes(include=[np.number]).columns:
                    col_min = df[col].min()
                    col_max = df[col].max()

                    if pd.api.types.is_integer_dtype(df[col]):
                        if col_min >= 0:  # unsigned
                            if col_max < 255:
                                df[col] = df[col].astype(np.uint8)
                            elif col_max < 65535:
                                df[col] = df[col].astype(np.uint16)
                            elif col_max < 4294967295:
                                df[col] = df[col].astype(np.uint32)
                        else:  # signed
                            if col_min >= -128 and col_max <= 127:
                                df[col] = df[col].astype(np.int8)
                            elif col_min >= -32768 and col_max <= 32767:
                                df[col] = df[col].astype(np.int16)
                            elif col_min >= -2147483648 and col_max <= 2147483647:
                                df[col] = df[col].astype(np.int32)

                    elif pd.api.types.is_float_dtype(df[col]):
                        if abs(col_max) < 3.4e38 and abs(col_min) < 3.4e38:
                            df[col] = df[col].astype(np.float32)

                self.tables[table_name] = df
                new_size = df.memory_usage(deep=True).sum()

                if new_size < original_size:
                    saved_mb = (original_size - new_size) / 1024 / 1024
                    logger.info(f"ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° {table_name}: ÑÑÐºÐ¾Ð½Ð¾Ð¼Ð»ÐµÐ½Ð¾ {saved_mb:.2f} MB")

            except Exception as e:
                logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ {table_name}: {e}")
