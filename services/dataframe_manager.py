# services/dataframe_manager.py
import pandas as pd
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import logging
from sqlalchemy import inspect, text
import numpy as np

logger = logging.getLogger(__name__)


@dataclass
class TableRelation:
    """ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""
    from_table: str
    to_table: str
    from_column: str
    to_column: str
    relation_type: str  # one_to_many, many_to_many, one_to_one


class DataFrameManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ DataFrame"""

    def __init__(self, engine):
        self.engine = engine
        self.tables: Dict[str, pd.DataFrame] = {}
        self.relations: List[TableRelation] = []
        self.table_schemas: Dict[str, Dict] = {}
        self.total_memory_usage = 0

    def load_all_tables(self, max_rows_per_table: int = 100000) -> Dict[str, pd.DataFrame]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð²ÑÐµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð² Ð¿Ð°Ð¼ÑÑ‚ÑŒ ÐºÐ°Ðº DataFrame"""
        inspector = inspect(self.engine)
        tables_loaded = 0

        logger.info("ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð²ÑÐµÑ… Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ð² DataFrame...")

        for table_name in inspector.get_table_names():
            if table_name == 'alembic_version':
                continue

            try:
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
                with self.engine.connect() as conn:
                    count_result = conn.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
                    row_count = count_result.scalar()

                if row_count == 0:
                    logger.info(f"ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÑÑ‚ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ {table_name}")
                    continue

                # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ‚Ñ€Ð¾Ðº Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ñ‚Ð°Ð±Ð»Ð¸Ñ†
                limit_clause = f" LIMIT {max_rows_per_table}" if row_count > max_rows_per_table else ""
                query = f"SELECT * FROM {table_name}{limit_clause}"

                # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
                df = pd.read_sql(query, self.engine)

                if not df.empty:
                    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
                    df = self._clean_dataframe(df)

                    self.tables[table_name] = df

                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑ…ÐµÐ¼Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
                    columns = inspector.get_columns(table_name)
                    primary_keys = inspector.get_pk_constraint(table_name).get('constrained_columns', [])

                    self.table_schemas[table_name] = {
                        'columns': {col['name']: str(col['type']) for col in columns},
                        'row_count': len(df),
                        'primary_keys': primary_keys,
                        'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024
                    }

                    tables_loaded += 1
                    memory_mb = df.memory_usage(deep=True).sum() / 1024 / 1024
                    self.total_memory_usage += memory_mb

                    logger.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° {table_name}: {len(df)} ÑÑ‚Ñ€Ð¾Ðº, {memory_mb:.2f} MB")

            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {table_name}: {e}")

        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸
        self._discover_relations(inspector)

        logger.info(f"ðŸŽ‰ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {tables_loaded} Ñ‚Ð°Ð±Ð»Ð¸Ñ†, {len(self.relations)} ÑÐ²ÑÐ·ÐµÐ¹, "
                    f"Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¾Ð±ÑŠÐµÐ¼: {self.total_memory_usage:.2f} MB")

        return self.tables

    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """ÐžÑ‡Ð¸Ñ‰Ð°ÐµÑ‚ DataFrame Ð¾Ñ‚ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹"""
        # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ inf Ð½Ð° NaN
        df = df.replace([np.inf, -np.inf], np.nan)

        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        for col in df.columns:
            if df[col].dtype == 'object':
                # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ None Ð² ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð´Ð»Ñ Ð¾Ð±ÑŠÐµÐºÑ‚Ð½Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
                df[col] = df[col].astype(str).replace('None', '')
            elif pd.api.types.is_numeric_dtype(df[col]):
                # Ð”Ð»Ñ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ NaN
                pass

        return df

    def _discover_relations(self, inspector):
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ð²Ð°ÐµÑ‚ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""
        for table_name in self.tables.keys():
            try:
                foreign_keys = inspector.get_foreign_keys(table_name)
                for fk in foreign_keys:
                    if fk['referred_table'] in self.tables:
                        relation = TableRelation(
                            from_table=table_name,
                            to_table=fk['referred_table'],
                            from_column=fk['constrained_columns'][0],
                            to_column=fk['referred_columns'][0],
                            relation_type='many_to_one'
                        )
                        self.relations.append(relation)

            except Exception as e:
                logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ FK Ð´Ð»Ñ {table_name}: {e}")

        logger.info(f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(self.relations)} ÑÐ²ÑÐ·ÐµÐ¹ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸")

    def join_tables(self, left_table: str, right_table: str,
                    join_type: str = 'inner', on: Optional[Dict[str, str]] = None) -> pd.DataFrame:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ JOIN Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""

        if left_table not in self.tables or right_table not in self.tables:
            raise ValueError(f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ñ‹ {left_table} Ð¸Ð»Ð¸ {right_table} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹")

        left_df = self.tables[left_table].copy()
        right_df = self.tables[right_table].copy()

        # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑÐ²ÑÐ·ÑŒ ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð°
        if on is None:
            relation = self._find_relation(left_table, right_table)
            if relation:
                on = {relation.from_column: relation.to_column}
            else:
                # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
                common_cols = set(left_df.columns).intersection(set(right_df.columns))
                if common_cols:
                    common_col = list(common_cols)[0]
                    on = {common_col: common_col}
                else:
                    raise ValueError(f"Ð¡Ð²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ {left_table} Ð¸ {right_table} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

        try:
            # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ JOIN
            result = pd.merge(
                left_df, right_df,
                left_on=list(on.keys()),
                right_on=list(on.values()),
                how=join_type,
                suffixes=('_left', '_right')
            )

            logger.info(f"JOIN Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½: {left_table} {join_type} {right_table}, "
                        f"Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {len(result)} ÑÑ‚Ñ€Ð¾Ðº")

            return result

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° JOIN: {e}")
            raise

    def _find_relation(self, table1: str, table2: str) -> Optional[TableRelation]:
        """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÐ²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ Ð´Ð²ÑƒÐ¼Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸"""
        # ÐŸÑ€ÑÐ¼Ð°Ñ ÑÐ²ÑÐ·ÑŒ
        for relation in self.relations:
            if relation.from_table == table1 and relation.to_table == table2:
                return relation

        # ÐžÐ±Ñ€Ð°Ñ‚Ð½Ð°Ñ ÑÐ²ÑÐ·ÑŒ
        for relation in self.relations:
            if relation.from_table == table2 and relation.to_table == table1:
                return TableRelation(
                    from_table=table1,
                    to_table=table2,
                    from_column=relation.to_column,
                    to_column=relation.from_column,
                    relation_type=relation.relation_type
                )

        return None

    def complex_query(self, operations: List[Dict[str, Any]]) -> pd.DataFrame:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑÐ¼Ð¸"""
        result_df = None

        for i, op in enumerate(operations):
            op_type = op.get('type')
            logger.info(f"Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ {i + 1}: {op_type}")

            if op_type == 'select':
                table_name = op['table']
                columns = op.get('columns', None)

                if table_name not in self.tables:
                    raise ValueError(f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° {table_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

                result_df = self.tables[table_name].copy()

                if columns:
                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
                    missing_cols = [col for col in columns if col not in result_df.columns]
                    if missing_cols:
                        logger.warning(f"ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹: {missing_cols}")
                        columns = [col for col in columns if col in result_df.columns]

                    if columns:
                        result_df = result_df[columns]

            elif op_type == 'join':
                if result_df is None:
                    raise ValueError("JOIN Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                right_table = op['table']
                join_type = op.get('how', 'inner')
                on = op.get('on')

                if right_table not in self.tables:
                    raise ValueError(f"Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° {right_table} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

                right_df = self.tables[right_table]

                if on:
                    result_df = pd.merge(
                        result_df, right_df,
                        left_on=on['left'],
                        right_on=on['right'],
                        how=join_type,
                        suffixes=('', '_right')
                    )
                else:
                    # ÐÐ²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·Ð¸ (ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ)
                    common_cols = set(result_df.columns).intersection(set(right_df.columns))
                    if common_cols:
                        common_col = list(common_cols)[0]
                        result_df = pd.merge(
                            result_df, right_df,
                            on=common_col,
                            how=join_type,
                            suffixes=('', '_right')
                        )
                    else:
                        raise ValueError(f"ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð´Ð»Ñ JOIN Ñ {right_table}")

            elif op_type == 'filter':
                if result_df is None:
                    raise ValueError("FILTER Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                condition = op['condition']
                try:
                    result_df = result_df.query(condition)
                except Exception as e:
                    logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ '{condition}': {e}")
                    # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ÑÑ‚ÑƒÑŽ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ
                    if 'column' in op and 'value' in op:
                        col = op['column']
                        val = op['value']
                        if col in result_df.columns:
                            result_df = result_df[result_df[col] == val]

            elif op_type == 'groupby':
                if result_df is None:
                    raise ValueError("GROUPBY Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                by = op['by']
                agg_dict = op.get('agg', {})

                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¸
                if isinstance(by, str):
                    by = [by]

                existing_by = [col for col in by if col in result_df.columns]
                if not existing_by:
                    logger.warning(f"ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹: {by}")
                    continue

                # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÑƒ
                if agg_dict:
                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð´Ð»Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸
                    valid_agg = {k: v for k, v in agg_dict.items() if k in result_df.columns}
                    if valid_agg:
                        result_df = result_df.groupby(existing_by).agg(valid_agg).reset_index()
                else:
                    # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° ÑÐ¾ ÑÑ‡ÐµÑ‚Ñ‡Ð¸ÐºÐ¾Ð¼
                    result_df = result_df.groupby(existing_by).size().reset_index(name='count')

            elif op_type == 'sort':
                if result_df is None:
                    raise ValueError("SORT Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                by = op['by']
                ascending = op.get('ascending', True)

                if isinstance(by, str):
                    by = [by]

                existing_by = [col for col in by if col in result_df.columns]
                if existing_by:
                    result_df = result_df.sort_values(existing_by, ascending=ascending)

            elif op_type == 'limit':
                if result_df is None:
                    raise ValueError("LIMIT Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ SELECT")

                n = op['n']
                result_df = result_df.head(n)

        if result_df is None:
            result_df = pd.DataFrame()

        logger.info(f"ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½, Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {len(result_df)} ÑÑ‚Ñ€Ð¾Ðº")
        return result_df

    def get_table_summary(self) -> Dict[str, Any]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¿Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼"""
        return {
            'total_tables': len(self.tables),
            'total_relations': len(self.relations),
            'total_memory_mb': self.total_memory_usage,
            'tables': {
                name: {
                    'rows': len(df),
                    'columns': len(df.columns),
                    'memory_mb': df.memory_usage(deep=True).sum() / 1024 / 1024
                }
                for name, df in self.tables.items()
            },
            'relations': [
                {
                    'from': rel.from_table,
                    'to': rel.to_table,
                    'on': f"{rel.from_column} -> {rel.to_column}"
                }
                for rel in self.relations
            ]
        }
